{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a72189",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, classification_report\n",
    "import requests\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "url = \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes_scale\"\n",
    "\n",
    "response = requests.get(url)\n",
    "data_io = io.BytesIO(response.content)\n",
    "\n",
    "X, y = load_svmlight_file(data_io)\n",
    "\n",
    "# Transform data to pandas DataFrame\n",
    "df = pd.DataFrame(X.toarray())\n",
    "df['target'] = y\n",
    "\n",
    "# Show data head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb303d",
   "metadata": {},
   "source": [
    "# 2. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for readable\n",
    "df.columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "\n",
    "# Show the information of the data\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532dc005",
   "metadata": {},
   "source": [
    "# 3. Splite the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ac02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features and labels\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "#split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_bigtrain, X_test, y_bigtrain, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=11)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_bigtrain, y_bigtrain, test_size=0.15, stratify=y_bigtrain, random_state=11)\n",
    "print([X_train.shape, y_train.shape,X_test.shape,y_test.shape,X_val.shape,y_val.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2905665",
   "metadata": {},
   "source": [
    "# 4. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140dda8d",
   "metadata": {},
   "source": [
    "# 4.1 Build baseline model (Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c31bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a logistic regression model as the baseline model\n",
    "baseline_model = Perceptron(max_iter=3000, random_state = 11)\n",
    "\n",
    "# Training the baseline model on the training set\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on validation sets\n",
    "y_val_pred_baseline = baseline_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfeb36",
   "metadata": {},
   "source": [
    "# 4.2 Evaluate the performance of baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the metrics of the baseline model\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score,\n",
    "    precision_score, roc_auc_score, f1_score\n",
    ")\n",
    "baseline_accuracy = accuracy_score(y_val, y_val_pred_baseline)\n",
    "baseline_recall = recall_score(y_val, y_val_pred_baseline, pos_label=-1)\n",
    "\n",
    "print(f'Baseline model performance on validation set:')\n",
    "print(f'Accuracy: {baseline_accuracy:.2f}')\n",
    "print(f'Recall: {baseline_recall:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733674c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "baseline_conf_matrix = confusion_matrix(y_val, y_val_pred_baseline, labels=[-1, 1])\n",
    "# Visual Confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(baseline_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['-1', '1'], yticklabels=['-1', '1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for Baseline model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70335e13",
   "metadata": {},
   "source": [
    "# 4.3 Build MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a Multi-layer Perceptron model\n",
    "mlp_model = MLPClassifier(max_iter=3000, random_state = 11)\n",
    "\n",
    "# Training the mlp model on the training sets\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on validation sets\n",
    "y_val_pred_mlp= mlp_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b4b97e",
   "metadata": {},
   "source": [
    "# 4.4 Evaluate the performance of MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6023f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the metrics of the mlp model\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score,\n",
    "    precision_score, roc_auc_score, f1_score\n",
    ")\n",
    "mlp_accuracy = accuracy_score(y_val, y_val_pred_mlp)\n",
    "mlp_recall = recall_score(y_val, y_val_pred_mlp, pos_label=-1)\n",
    "print(f'mlp model performance on validation set:')\n",
    "print(f'Accuracy: {mlp_accuracy:.2f}')\n",
    "print(f'Recall: {mlp_recall:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ac65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "mlp_conf_matrix = confusion_matrix(y_val, y_val_pred_mlp, labels=[-1, 1])\n",
    "# Visual Confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(mlp_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['-1', '1'], yticklabels=['-1', '1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for mlp model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a7f18",
   "metadata": {},
   "source": [
    "# 5 Model optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be8f25",
   "metadata": {},
   "source": [
    "# 5.1 Define parameter and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fec5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "import numpy as np\n",
    "\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(64,), (128,), (256,), (128, 64), (256, 128), (256, 128, 64)],\n",
    "    'learning_rate_init': [0.0001, 0.001, 0.01, 0.1], \n",
    "    'activation': ['relu', 'tanh', 'logistic']\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV\n",
    "mlp_search = RandomizedSearchCV(MLPClassifier(max_iter=4000, random_state=11), \n",
    "                                mlp_param_grid,\n",
    "                                n_iter=10,  \n",
    "                                scoring={'accuracy': 'accuracy', 'recall': make_scorer(recall_score, pos_label=-1)},\n",
    "                                refit='recall',\n",
    "                                cv=10, \n",
    "                                error_score='raise')\n",
    "\n",
    "mlp_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0cdeb0",
   "metadata": {},
   "source": [
    "# 5.2 Show results for all combinations of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the results of recall and accuracy\n",
    "cv_results = mlp_search.cv_results_\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'hidden_layer_sizes': [param['hidden_layer_sizes'] for param in cv_results['params']],\n",
    "    'learning_rate_init': [param['learning_rate_init'] for param in cv_results['params']],\n",
    "    'activation': [param['activation'] for param in cv_results['params']],\n",
    "    'mean_test_accuracy': cv_results['mean_test_accuracy'],\n",
    "    'mean_test_recall': cv_results['mean_test_recall'],  # recall 结果\n",
    "    'std_test_accuracy': cv_results['std_test_accuracy'],\n",
    "    'std_test_recall': cv_results['std_test_recall']\n",
    "})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cade171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df.index, results_df['mean_test_accuracy'], marker='o', label='Accuracy')\n",
    "plt.plot(results_df.index, results_df['mean_test_recall'], marker='x', label='Recall')\n",
    "plt.title('Hyperparameter Combinations: Impact on Accuracy and Recall')\n",
    "plt.xlabel('Hyperparameter Combination Index')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c361015",
   "metadata": {},
   "source": [
    "# 5.3 Select the best model and evaluate the performance of best model on validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07521f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the combinations of parameters of best model\n",
    "bestmlp = mlp_search.best_estimator_\n",
    "print(f\"Best parameters for MLP: {bestmlp}\")\n",
    "\n",
    "best_mlp_p = bestmlp.predict(X_val)\n",
    "# Evaluate the performance of best model on validation sets\n",
    "best_mlp_accuracy = accuracy_score(y_val, best_mlp_p)\n",
    "best_mlp_recall = recall_score(y_val, best_mlp_p, pos_label=-1)\n",
    "print(f\"Best MLP Model - Accuracy: {best_mlp_accuracy}, Recall: {best_mlp_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f93920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual confusion matrix\n",
    "\n",
    "# Confusion matrix\n",
    "best_conf_matrix = confusion_matrix(y_val, best_mlp_p, labels=[-1, 1])\n",
    "# Visual Confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(best_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['-1', '1'], yticklabels=['-1', '1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for best mlp model')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8de132",
   "metadata": {},
   "source": [
    "# 5.4 Visualize the training loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692d997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "# Assuming bestmlp already has the trained model and X_val, y_val are available\n",
    "train_loss = bestmlp.loss_curve_  # Loss values during training from MLPClassifier\n",
    "\n",
    "# Calculate validation loss\n",
    "val_pred_proba = bestmlp.predict_proba(X_val)\n",
    "val_loss = log_loss(y_val, val_pred_proba)\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss, label=\"Training Loss\", color='blue')\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46113f3e",
   "metadata": {},
   "source": [
    "# 5.5 Evaluate the performance of best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_pred = bestmlp.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "test_recall = recall_score(y_test, test_pred, pos_label=-1)\n",
    "print(f\"Best Model on Test Set - Accuracy: {test_accuracy}, Recall: {test_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "# Visual Confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(test_cm, annot=True, fmt='d', cmap='Blues', xticklabels=['-1', '1'], yticklabels=['-1', '1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(\"Best Model Confusion Matrix on Test Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac6d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 (UML)",
   "language": "python",
   "name": "uml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
